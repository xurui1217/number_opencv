import cv2
import time
import numpy as np 
import pygame
import math
import os
import tensorflow as tf 
from sys import exit
from PIL import Image
from pygame.locals import *
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
cwd = os.getcwd()
####################################################################################
#从这里开始写图像处理的程序
def rotate(img,angle,x0,y0):     
	height = img.shape[0]  
	width = img.shape[1]  
	#scale = math.sqrt(pow(height,2)+pow(width,2))/min(height, width)  
      
    #print 'scale %f\n' %scale  
          
	rotateMat = cv2.getRotationMatrix2D((x0, y0), angle, 1)  
	rotateImg = cv2.warpAffine(img, rotateMat, (width, height))  
    #cv2.imshow('rotateImg',rotateImg)  
    #cv2.waitKey(0)  
      
	return rotateImg #rotated image

def getcenter(box):
	x0=int((box[2][0]+box[0][0])/2)
	y0=int((box[2][1]+box[0][1])/2)
	return x0,y0

def getangle(box,x0,y0):
	if box[2][0]-box[1][0]<box[3][0]-box[2][0]:
		#nishizheng,angle+
		#左边的中心点坐标为x1，x2
		x1=int((box[1][0]+box[2][0])/2)
		y1=int((box[1][1]+box[2][1])/2)
		angle=math.atan((y0-y1)/(x0-x1))*180/math.pi
	else:
		x1=int((box[1][0]+box[0][0])/2)
		y1=int((box[1][1]+box[0][1])/2)
		angle=-math.atan((y1-y0)/(x0-x1))*180/math.pi
	return angle


def createsample(img):
	gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) 
	ret,binary = cv2.threshold(gray,90,255,cv2.THRESH_BINARY)
	blurred = cv2.blur(binary, (10,10))
	#cv2.imwrite('erzhihua.jpg',binary)  
	cntout,contours,hierarchy=cv2.findContours(blurred,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  
	rect = cv2.minAreaRect(contours[0])	
	#cv2.imshow("img", img) 
	box = cv2.boxPoints(rect)
	box = np.int0(box)
	cv2.drawContours(img,[box],0,(0,0,255),2)
	#cv2.imwrite('kuang.jpg',img)
	x0,y0=getcenter(box)
	angle=getangle(box,x0,y0)
	img_spin=rotate(img,angle,x0,y0)
	#cv2.imwrite('spin.jpg',img_spin)
	#cv2.imshow('spin',img_spin)
	#cv2.waitKey(0) 
	return img_spin

def adjustimg(img): 
	gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  
	ret,binary = cv2.threshold(gray,90,255,cv2.THRESH_BINARY)  
	#cv2.imshow("bb", binary)   
	blurred = cv2.blur(binary, (10,10))
	cntout,contours,hierarchy=cv2.findContours(blurred,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)  
	#cv2.drawContours(img,contours,-1,(0,0,255),3)  
	x, y, w, h = cv2.boundingRect(contours[0])
	#cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
	
	#print(x,y,w,h)
	img_out=img[y:y+h,x:x+w]
	return img_out

####################################################################################
#神经网络的函数定义	
def read_and_decode(filename):
    #根据文件名生成一个队列
    filename_queue = tf.train.string_input_producer([filename])

    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)   #返回文件名和文件
    features = tf.parse_single_example(serialized_example,
                                       features={
                                           'label': tf.FixedLenFeature([], tf.int64),
                                           'img_raw' : tf.FixedLenFeature([], tf.string),
                                       })

    img = tf.decode_raw(features['img_raw'], tf.uint8)
    img = tf.reshape(img,(784,))
    
    #这里不reshape的话就是训练集的标准形式
    #为什么要减去0.5？
    #img = tf.cast(img, tf.float32) * (1 / 255) - 0.5
    img = tf.cast(img, tf.float32) * (1 / 255) 
    label = tf.cast(features['label'], tf.int32)
    return img, label


def write_to_record():
	writer = tf.python_io.TFRecordWriter("numtrain.tfrecords")
	#在这里被坑了好久！！！fuck了
	for index, name in enumerate(classes):
		class_path =cwd+"\\"+name+'\\'
		for img_name in os.listdir(class_path):
			img_path = class_path + img_name
  			#img = Image.open(img_path)
  			#img = img.resize((150, 200))
  			#img_raw = img.tobytes()
			img=cv2.imread(img_path,0)
			img= cv2.resize(img, (28,28))
	  		#转化成比特位存储的时候不用特意的变成784的标准形式
	  		#img_out =img.reshape((784,1))
	  		#print(img_out.shape)
			img_raw=img.tobytes()
	  		#print(index, name)
	  		#print(img_raw)             
	  		#将图片转化为原生bytes
			example = tf.train.Example(features=tf.train.Features(feature={
				"label": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),
				'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))
			}))
			writer.write(example.SerializeToString())  #序列化为字符串
	writer.close()


def record_to_batch(batchnum):
	#读出来record里面的内容，并且应用于训练集

	#使用shuffle_batch可以随机打乱输入
	img_batch, label_batch = tf.train.shuffle_batch([img, label],batch_size=batchnum, capacity=100,min_after_dequeue=50)
	label_batch_out = tf.one_hot(label_batch,10,1,0)
	#print(label_batch,label_batch_out)
	#print(img_batch.shape)
	#print(labels.shape)
	threads = tf.train.start_queue_runners(sess=sess)
	return img_batch,label_batch_out




def weight_variable(shape):
	initial=tf.truncated_normal(shape,stddev=0.1)
	return tf.Variable(initial)

def bias_variable(shape):
	initial=tf.constant(0.1,shape=shape)
	return tf.Variable(initial)

def conv2d(x,w):
	return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding='SAME')

def max_pool_2x2(x):
	return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

def img_process(img):
	print(img.shape)

def createfont(number_know):
	myfont=pygame.font.SysFont("arial",64)
	mysurface=myfont.render("adasdasdadsxxxxxrrr",True,(0,0,0))
	pygame.image.save(mysurface,"num_know.png")
	img=cv2.imread('num_know.png')
	cv2.imshow('asdasd',img)
	cv2.waitKey(0)

####################################################################################
#主程序
pygame.init()
interval = 0.001   	# 捕获图像的间隔，单位：秒
num_frames = 1000   	# 捕获图像的总帧数可以设置的大一些     

# VideoCapture(0)表示打开默认的相机
cap = cv2.VideoCapture(1)

# 获取捕获的分辨率
size =(int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))
       
pygame.display.set_caption('视频窗口')   
screen = pygame.display.set_mode(size) 

# 对于一些低画质的摄像头，前面的帧可能不稳定，略过
for i in range(42):
    cap.read()

#神经网络初始化：
x=tf.placeholder(tf.float32,shape=[None,784])
y_=tf.placeholder(tf.float32,shape=[None,10])

w_conv1=weight_variable([5,5,1,32])
b_conv1=bias_variable([32])
x_image=tf.reshape(x,[-1,28,28,1])

h_conv1=tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)
h_pool1=max_pool_2x2(h_conv1)

w_conv2=weight_variable([5,5,32,64])
b_conv2=bias_variable([64])

h_conv2=tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)
h_pool2=max_pool_2x2(h_conv2)

w_fc1=weight_variable([7*7*64,1024])
b_fc1=bias_variable([1024])
h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])
h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,w_fc1)+b_fc1)

keep_prob=tf.placeholder(tf.float32)
h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob)

w_fc2=weight_variable([1024,10])
b_fc2=bias_variable([10])
y_conv=tf.matmul(h_fc1_drop,w_fc2)+b_fc2

saver=tf.train.Saver() 
#构建完成
print('finish create network')

try:
	while True:
		for event in pygame.event.get():
			if event.type == QUIT:
				exit()
		i=i+1
		ret,frame = cap.read()
		print('Frame {} is captured.'.format(i))
		cv2.imwrite('ceshi.jpg',frame)
		img=cv2.imread('ceshi.jpg')
		#用pygame模块来让我们看图像
		image = pygame.image.load('ceshi.jpg')
		screen.blit(image, (0,0))
		


		#处理图像
		img_spinned=createsample(img)
		#cv2.imshow('spin',img_spinned)
		img_adjust=adjustimg(img_spinned)
		#cv2.imshow('adjusted',img_adjust)
		img_adjust=cv2.resize(img_adjust,(600,300))
		img_adjust_w=img_adjust.shape[1]
		img_adjust_h=img_adjust.shape[0]
		#print(img_adjust_w,img_adjust_h)
		#cv2.imwrite('adjustceshi.jpg',img_adjust)
		img_1=img_adjust[int(img_adjust_h/6):int(img_adjust_h*5/6),0:int(img_adjust_w/4)]
		img_2=img_adjust[int(img_adjust_h/6):int(img_adjust_h*5/6),int(img_adjust_w/4):int(img_adjust_w/2)]
		img_3=img_adjust[int(img_adjust_h/6):int(img_adjust_h*5/6),int(img_adjust_w/2):int(img_adjust_w*0.75)]
		img_4=img_adjust[int(img_adjust_h/6):int(img_adjust_h*5/6),int(img_adjust_w*0.75):int(img_adjust_w)]
		#print(img_1.shape)
		img_1_s= cv2.cvtColor(img_1, cv2.COLOR_BGR2GRAY)
		img_2_s= cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)
		img_3_s= cv2.cvtColor(img_3, cv2.COLOR_BGR2GRAY)
		img_4_s= cv2.cvtColor(img_4, cv2.COLOR_BGR2GRAY)
		#print(img_1_s.shape)
		img_1_s= cv2.resize(img_1_s, (28,28))	
		img_2_s= cv2.resize(img_2_s, (28,28))
		img_3_s= cv2.resize(img_3_s, (28,28))
		img_4_s= cv2.resize(img_4_s, (28,28))
		#print(img_1_s.shape)
		img_1_s=img_1_s.reshape(1,784)
		img_2_s=img_2_s.reshape(1,784)
		img_3_s=img_3_s.reshape(1,784)
		img_4_s=img_4_s.reshape(1,784)
		#想办法把图像的切片组合成我们需要的数据集格式[4,784]
		#这里搞了我半天，被灰度化搞崩了，通道数太多就不能reshape！！！
		img_summary= np.concatenate((img_1_s,img_2_s,img_3_s,img_4_s),axis=0)
		print('finish img process')


		#进网络出结果
		with tf.Session() as sess:
			sess.run(tf.global_variables_initializer())
			#训练过程
			saver.restore(sess,cwd+'\\'+'juanji')
			img_batch=img_summary
			label_batch=[[0,0,0,0,0,0,0,0,0,0]]
			#train_accuracy = accuracy.eval(feed_dict={x:img_batch,y_:label_batch, keep_prob: 1.0})
			#print("step, training accuracy:%g"%(train_accuracy))
			y_out=sess.run(y_conv,feed_dict={x:img_batch,y_:label_batch, keep_prob: 1.0})
			
			print(np.argmax(y_out,1))
		#print(img_summary.shape)
		#pygame.display.flip()
		num_know=np.argmax(y_out,1)
		num_know_int=num_know[0]*1000+num_know[1]*100+num_know[2]*10+num_know[3]
		#检测完之后输出结果
		myfont=pygame.font.SysFont("arial",64)
		mysurface=myfont.render(str(num_know_int),True,(255,255,255))
		#pygame.image.save(mysurface,"123.png")
		#img=cv2.imread('123.png')
		screen.blit(mysurface, (0, 0))
		#img_process(img)
		time.sleep(interval)
		pygame.display.update()
except KeyboardInterrupt:
	# 提前停止捕获
	print('Stopped! {}/{} frames captured!'.format(i, num_frames))
except ZeroDivisionError:
	print('not in correct location')
except cv2.error:
	print('find no file')

# 释放资源收工了
cap.release()
cv2.destroyAllWindows()
